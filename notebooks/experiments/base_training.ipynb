{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base experiment notebook\n",
    "\n",
    "This notebook is the template for all experiments.\n",
    "\n",
    "It contains the basic code to run an experiment, and it is the starting point for all other notebooks in the folder `experiments`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import callbacks, seed_everything\n",
    "from torch import nn\n",
    "\n",
    "from nlp_assemblee.simple_trainer import LitModel, load_embedding, process_predictions\n",
    "from nlp_assemblee.simple_visualisation import (\n",
    "    calculate_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_network_graph,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, workers=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change between experiments\n",
    "FEATURES = True\n",
    "TEXT_VARS = [\"intervention\", \"titre_regexed\", \"contexte\"]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "CALLBACKS = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", min_delta=0.01, check_finite=True, patience=10\n",
    "    ),\n",
    "    callbacks.ModelSummary(max_depth=-1),\n",
    "    callbacks.Timer(duration=\"00:03:00:00\", interval=\"epoch\"),\n",
    "    callbacks.RichProgressBar(),\n",
    "    callbacks.LearningRateMonitor(logging_interval=\"epoch\", log_momentum=False),\n",
    "]\n",
    "\n",
    "OPTIMIZER_TYPE = \"Adam\"\n",
    "OPTIMIZER_KWARGS = {}\n",
    "LR = 1e-4\n",
    "LOSS = \"CrossEntropyLoss\"\n",
    "\n",
    "SCHEDULER_KWARGS = {\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\": 0.1,\n",
    "    \"patience\": 5,\n",
    "    \"interval\": \"epoch\",\n",
    "    \"frequency\": 1,\n",
    "    \"strict\": True,\n",
    "    \"monitor\": \"val_loss\",\n",
    "}\n",
    "# SCHEDULER_KWARGS = {\n",
    "#     \"scheduler\": \"OneCycleLR\",\n",
    "#     \"max_lr\": 5e-3,\n",
    "#     \"pct_start\": 0.3,\n",
    "#     \"epochs\": 30,\n",
    "#     \"steps_per_epoch\": 100,\n",
    "#     \"interval\": \"epoch\",\n",
    "#     \"frequency\": 1,\n",
    "#     \"strict\": True\n",
    "# }\n",
    "\n",
    "\n",
    "# Doesn't change between experiments\n",
    "LABEL_VAR = \"label\"\n",
    "DATA_ROOT = \"../../data/\"\n",
    "NUM_WORKERS = 12\n",
    "PREFETCH_FACTOR = 4\n",
    "PIN_MEMORY = True\n",
    "ACCELERATOR = \"gpu\"\n",
    "DEVICE = \"cuda\"\n",
    "LOG_EVERY_N_STEPS = 50\n",
    "CHECK_VAL_EVERY_N_EPOCH = 3\n",
    "DETERMINISTIC = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "MODEL_FOLDER = f\"../../data/precomputed/{MODEL_NAME}\"\n",
    "RESULTS_PATH = f\"../../results/{MODEL_NAME}/\"\n",
    "LOGGER = pl.loggers.TensorBoardLogger(RESULTS_PATH, name=MODEL_NAME, log_graph=True)\n",
    "Path(RESULTS_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, root, embed_dim, inter_dim, dropout=0.2, freeze=True):\n",
    "        super().__init__()\n",
    "        self.example_input_array = {\n",
    "            \"text\": {\n",
    "                \"intervention\": torch.randn(32, 768),\n",
    "                \"titre_regexed\": torch.randint(100, (32,)).int(),\n",
    "                \"contexte\": torch.randint(100, (32,)).int(),\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.inter_dim = inter_dim\n",
    "        self.dropout = dropout\n",
    "        self.freeze = freeze\n",
    "\n",
    "        self.titre_embeddings = load_embedding(root, \"titre_regexed\", freeze=freeze)\n",
    "        self.titre_fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, inter_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.contexte_embeddings = load_embedding(root, \"contexte\", freeze=freeze)\n",
    "        self.contexte_fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, inter_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.intervention_fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, inter_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(inter_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, **x):\n",
    "        intervention = x[\"text\"][\"intervention\"]\n",
    "        titre_regexed = x[\"text\"][\"titre_regexed\"]\n",
    "        contexte = x[\"text\"][\"contexte\"]\n",
    "\n",
    "        intervention_repr = self.intervention_fc(intervention)\n",
    "\n",
    "        titre_emb = self.titre_embeddings(titre_regexed)\n",
    "        titre_repr = self.titre_fc(titre_emb)\n",
    "\n",
    "        contexte_emb = self.contexte_embeddings(contexte)\n",
    "        contexte_repr = self.contexte_fc(contexte_emb)\n",
    "\n",
    "        pooled_repr = intervention_repr + titre_repr + contexte_repr\n",
    "\n",
    "        logits = self.mlp(pooled_repr)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET = Net(MODEL_FOLDER, 768, 1024, dropout=0.2, freeze=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the trainer and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitModel(\n",
    "    NET,\n",
    "    optimizer_type=OPTIMIZER_TYPE,\n",
    "    learning_rate=LR,\n",
    "    optimizer_kwargs=OPTIMIZER_KWARGS,\n",
    "    scheduler_kwargs=SCHEDULER_KWARGS,\n",
    "    criterion_type=LOSS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    loader_kwargs={\n",
    "        \"root\": MODEL_FOLDER,\n",
    "        \"text_vars\": TEXT_VARS,\n",
    "        \"use_features\": FEATURES,\n",
    "        \"label_var\": LABEL_VAR,\n",
    "        \"num_workers\": NUM_WORKERS,\n",
    "        \"prefetch_factor\": PREFETCH_FACTOR,\n",
    "        \"pin_memory\": PIN_MEMORY,\n",
    "    },\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=ACCELERATOR,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=LOGGER,\n",
    "    callbacks=CALLBACKS,\n",
    "    deterministic=DETERMINISTIC,\n",
    "    log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "    check_val_every_n_epoch=CHECK_VAL_EVERY_N_EPOCH,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lit_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(ckpt_path=\"best\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(results)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(RESULTS_PATH) / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_dict = {\n",
    "    \"last_epoch\": trainer.current_epoch,\n",
    "    \"log_dir\": trainer.log_dir,\n",
    "    \"ckpt_path\": trainer.ckpt_path,\n",
    "    \"total_parameters\": pl.utilities.model_summary.summarize(lit_model).total_parameters,\n",
    "    \"trainable_parameters\": pl.utilities.model_summary.summarize(lit_model).trainable_parameters,\n",
    "    \"model_size\": pl.utilities.model_summary.summarize(lit_model).model_size,\n",
    "    \"hparams\": dict(lit_model.hparams_initial),\n",
    "    \"time_elapsed\": trainer.callbacks[2].time_elapsed(),\n",
    "    \"metrics\": metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(RESULTS_PATH) / \"logs.json\", \"w\") as f:\n",
    "    json.dump(logs_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_fig = plot_confusion_matrix(results, figsize=(6, 6), normalized=None)\n",
    "confusion_fig.savefig(Path(RESULTS_PATH) / \"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_true_fig = plot_confusion_matrix(results, figsize=(6, 6), normalized=\"true\")\n",
    "confusion_true_fig.savefig(Path(RESULTS_PATH) / \"confusion_matrix_true_normed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_fig = plot_roc_curve(results, figsize=(6, 6), palette=\"deep\")\n",
    "roc_fig.savefig(Path(RESULTS_PATH) / \"roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_fig = plot_precision_recall_curve(results, figsize=(6, 6), palette=\"deep\")\n",
    "pr_fig.savefig(Path(RESULTS_PATH) / \"precision_recall_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_fig = plot_network_graph(NET, device=DEVICE, model_name=MODEL_NAME, path=RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.to_onnx(Path(RESULTS_PATH) / \"textual_camembert.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-11-7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "290de4d201867099a7cec8aa5bca78d01a6c85d7bcab7b52f8e97114ad853450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

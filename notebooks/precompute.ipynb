{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precompute the embeddings for the training and test set\n",
    "\n",
    "This notebook precomputes the embeddings of the data.\n",
    "\n",
    "This process is lengthy and can be done once and for all. It takes about 3 hours on a single GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from nlp_assemblee.datasets import build_dataset_and_dataloader_from_config\n",
    "from nlp_assemblee.models import build_classifier_from_config\n",
    "from nlp_assemblee.simple_precompute import (\n",
    "    get_embeddings_dict,\n",
    "    get_embeddings_dict_from_hugging,\n",
    "    get_embeddings_list,\n",
    "    get_embeddings_list_from_hugging,\n",
    "    get_embeddings_list_unbatched,\n",
    "    get_embeddings_matrix,\n",
    "    plot_proj_from_emb_dict,\n",
    "    save_embedding_matrix,\n",
    "    save_embedding_matrix_from_list,\n",
    "    train_test_val_split,\n",
    ")\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/processed/14th_merged_data_short.pkl\")\n",
    "df = df[\n",
    "    [\n",
    "        \"nom\",\n",
    "        \"groupe\",\n",
    "        \"date_seance\",\n",
    "        \"nb_mots_approx\",\n",
    "        \"profession\",\n",
    "        \"titre\",\n",
    "        \"titre_complet\",\n",
    "        \"intervention\",\n",
    "        \"sexe\",\n",
    "        \"n_y_naissance\",\n",
    "        \"label\",\n",
    "    ]\n",
    "]\n",
    "reg = \"(article|l'article)\\s*(\\d+[^\\w\\s]*|premier|deuxième|troisième|[^\\w\\s]*\\d+[^\\w\\s]*)\"\n",
    "df[\"titre_regexed\"] = df[\"titre\"].str.replace(reg, \"Article X\", regex=True)\n",
    "df[\"contexte\"] = (\n",
    "    df[\"titre_complet\"].str.split(\" > \").apply(lambda x: x[0] if len(x) > 1 else \"Sans contexte\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, idx_test = train_test_val_split(\n",
    "    df[\"label\"], train_pc=0.5, val_pc=0.2, stratify=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniLM-L12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../data/precomputed/{model_name}\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict(model, df, \"profession\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict(model, df, \"titre_regexed\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict(model, df, \"contexte\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict(\n",
    "    model, df, \"titre_complet\", batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list(model, df, \"intervention\", batch_size=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, idx_test = train_test_val_split(\n",
    "    df[\"label\"], train_pc=0.5, val_pc=0.2, stratify=True, random_state=42\n",
    ")\n",
    "\n",
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilUse-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distiluse-base-multilingual-cased-v2\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../data/precomputed/{model_name}\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict(model, df, \"profession\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_proj_from_emb_dict(\"umap\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict(model, df, \"titre_regexed\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict(model, df, \"contexte\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict(\n",
    "    model, df, \"titre_complet\", batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list(model, df, \"intervention\", batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNET-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../data/precomputed/{model_name}\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict(model, df, \"profession\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict(model, df, \"titre_regexed\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tnse_fig = plot_proj_from_emb_dict(\"tnse\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict(model, df, \"contexte\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict(\n",
    "    model, df, \"titre_complet\", batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list(model, df, \"intervention\", batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camembert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dangvantuan/sentence-camembert-base\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/precomputed/camembert-base\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_matrix, profession_to_int = get_embeddings_matrix(model, df, \"profession\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix_from_list(profession_matrix, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_matrix.T, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_matrix.T, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", profession_matrix.T, profession_to_int, df, \"profession\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_matrix, titre_to_int = get_embeddings_matrix(model, df, \"titre_regexed\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix_from_list(titre_matrix, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_matrix.T, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_matrix.T, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_matrix.T, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_matrix, contexte_to_int = get_embeddings_matrix(model, df, \"contexte\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix_from_list(contexte_matrix, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_matrix.T, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_matrix.T, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_matrix.T, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_matrix, titre_complet_to_int = get_embeddings_matrix(\n",
    "    model, df, \"titre_complet\", batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix_from_list(titre_complet_matrix, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_matrix.T, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_matrix.T, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_matrix.T, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = model.encode(\n",
    "    df[\"intervention\"].to_list(), batch_size=128, show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path / \"precomputed_train.pkl\", \"rb\") as f:\n",
    "    intervention_list = pickle.load(f)[\"intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP(n_components=2)\n",
    "proj = fit.fit_transform(intervention_list)\n",
    "proj_df = pd.DataFrame(proj, columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    proj_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=df[\"label\"].values[idx_train],\n",
    "    color_continuous_scale=px.colors.diverging.Temps,\n",
    ")\n",
    "\n",
    "fig_path = Path(path) / \"intervention/images\"\n",
    "fig_path.mkdir(exist_ok=True, parents=True)\n",
    "fig.write_image(fig_path / \"umap.png\")\n",
    "fig.write_html(fig_path / \"umap.html\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = PCA(n_components=2)\n",
    "proj = fit.fit_transform(intervention_list)\n",
    "proj_df = pd.DataFrame(proj, columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    proj_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=df[\"label\"].values[idx_train],\n",
    "    color_continuous_scale=px.colors.diverging.Temps,\n",
    ")\n",
    "\n",
    "fig_path = Path(path) / \"intervention/images\"\n",
    "fig_path.mkdir(exist_ok=True, parents=True)\n",
    "fig.write_image(fig_path / \"pca.png\")\n",
    "fig.write_html(fig_path / \"pca.html\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../data/precomputed/{model_name}\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"profession\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_regexed\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"contexte\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_complet\", batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list_from_hugging(\n",
    "    model, tokenizer, df, \"intervention\", batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilcamembert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cmarkea/distilcamembert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/precomputed/distilcamembert-base\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"profession\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_regexed\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"contexte\", batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_complet\", batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list_from_hugging(\n",
    "    model, tokenizer, df, \"intervention\", batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "pooled_output = \"pooled\"\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"../data/precomputed/{model_name}\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"profession\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_regexed\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"contexte\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_complet\", batch_size=16, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list_from_hugging(\n",
    "    model, tokenizer, df, \"intervention\", batch_size=128, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "pooled_output = \"mean\"\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/precomputed/xlm-roberta-base\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"profession\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_regexed\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"contexte\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_complet\", batch_size=16, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list_from_hugging(\n",
    "    model, tokenizer, df, \"intervention\", batch_size=128, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"prajjwal1/bert-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "pooled_output = \"mean\"\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/precomputed/bert-tiny\")\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict, profession_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"profession\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(profession_dict, profession_to_int, \"profession\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", profession_dict, profession_to_int, df, \"profession\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", profession_dict, profession_to_int, df, \"profession\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_dict, titre_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_regexed\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_dict, titre_to_int, \"titre_regexed\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", titre_dict, titre_to_int, df, \"titre_regexed\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", titre_dict, titre_to_int, df, \"titre_regexed\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexte_dict, contexte_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"contexte\", batch_size=8, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(contexte_dict, contexte_to_int, \"contexte\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\"umap\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "tsne_fig = plot_proj_from_emb_dict(\"tsne\", contexte_dict, contexte_to_int, df, \"contexte\", path)\n",
    "pca_fig = plot_proj_from_emb_dict(\"pca\", contexte_dict, contexte_to_int, df, \"contexte\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre_complet_dict, titre_complet_to_int = get_embeddings_dict_from_hugging(\n",
    "    model, tokenizer, df, \"titre_complet\", batch_size=16, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix(titre_complet_dict, titre_complet_to_int, \"titre_complet\", path)\n",
    "umap_fig = plot_proj_from_emb_dict(\n",
    "    \"umap\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "tsne_fig = plot_proj_from_emb_dict(\n",
    "    \"tsne\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")\n",
    "pca_fig = plot_proj_from_emb_dict(\n",
    "    \"pca\", titre_complet_dict, titre_complet_to_int, df, \"titre_complet\", path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = get_embeddings_list_from_hugging(\n",
    "    model, tokenizer, df, \"intervention\", batch_size=128, pooled_output=pooled_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"profession\": df[\"profession\"].map(profession_to_int).values,\n",
    "    \"titre_regexed\": df[\"titre_regexed\"].map(titre_to_int).values,\n",
    "    \"titre_complet\": df[\"titre_complet\"].map(titre_complet_to_int).values,\n",
    "    \"contexte\": df[\"contexte\"].map(contexte_to_int).values,\n",
    "    \"intervention\": intervention_list,\n",
    "    \"sexe\": df[\"sexe\"].map({\"H\": 0.0, \"F\": 1.0}).values,\n",
    "    \"n_y_naissance\": df[\"n_y_naissance\"].values,\n",
    "    \"label\": df[\"label\"].values,\n",
    "}\n",
    "\n",
    "train_records = {k: v[idx_train] for k, v in records.items()}\n",
    "val_records = {k: v[idx_val] for k, v in records.items()}\n",
    "test_records = {k: v[idx_test] for k, v in records.items()}\n",
    "\n",
    "with open(path / \"precomputed_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_records, f)\n",
    "\n",
    "with open(path / \"precomputed_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_records, f)\n",
    "\n",
    "with open(path / \"precomputed_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_records, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-11-7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "290de4d201867099a7cec8aa5bca78d01a6c85d7bcab7b52f8e97114ad853450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"last_epoch": 27, "log_dir": "../../results/lm_model_selection/xlm-roberta-base/lightning_logs/version_0", "ckpt_path": "/home/gwatk/Documents/MVA/DL/NLP_Assemblee/results/lm_model_selection/xlm-roberta-base/lightning_logs/epoch=27-step=8568.ckpt", "total_parameters": 6641666, "trainable_parameters": 2363906, "model_size": 26.566664, "hparams": {"optimizer_type": "Adam", "learning_rate": 0.005, "optimizer_kwargs": {"weight_decay": 0.0001}, "scheduler_kwargs": {"scheduler": "ReduceLROnPlateau", "mode": "min", "factor": 0.1, "patience": 3, "interval": "epoch", "frequency": 1, "strict": true, "monitor": "val_loss"}, "criterion_type": "CrossEntropyLoss", "batch_size": 512, "loader_kwargs": {"root": "../../data/precomputed/xlm-roberta-base", "text_vars": ["intervention", "titre_regexed", "contexte"], "use_features": true, "label_var": "label", "drop_center": true, "num_workers": 12, "prefetch_factor": 4, "pin_memory": true}}, "time_elapsed": 278.52765171099963, "metrics": {"log_loss": 0.5548499973214523, "accuracy": 0.7091246441100886, "balanced_accuracy": 0.6925159435418533, "recall": 0.5907886017229954, "precision": 0.6737689669205279, "f1_score": 0.6295561953392363, "AUC": 0.7770660995164373, "jaccard_weighted": 0.45938125532631746, "matthews_weighted": 0.39409823820689444, "hamming_loss": 0.29087535588991137, "confusion_matrix": [[43322, 11223], [16055, 23179]], "confusion_matrix_true_normed": [[0.7942432853607113, 0.20575671463928866], [0.40921139827700465, 0.5907886017229954]], "confusion_matrix_pred_normed": [[0.7296091079037338, 0.3262310330794721], [0.2703908920962662, 0.6737689669205279]], "confusion_matrix_all_normed": [[0.46195843419102356, 0.11967498053935316], [0.17120037535055824, 0.24716620991906504]]}}

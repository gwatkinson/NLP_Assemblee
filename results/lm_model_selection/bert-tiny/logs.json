{"last_epoch": 18, "log_dir": "../../results/lm_model_selection/bert-tiny/lightning_logs/version_0", "ckpt_path": "/home/gwatk/Documents/MVA/DL/NLP_Assemblee/results/lm_model_selection/bert-tiny/lightning_logs/epoch=18-step=5814.ckpt", "total_parameters": 1602306, "trainable_parameters": 889346, "model_size": 6.409224, "hparams": {"optimizer_type": "Adam", "learning_rate": 0.005, "optimizer_kwargs": {"weight_decay": 0.0001}, "scheduler_kwargs": {"monitor": "val_loss"}, "criterion_type": "CrossEntropyLoss", "batch_size": 512, "loader_kwargs": {"root": "../../data/precomputed/bert-tiny", "text_vars": ["intervention", "titre_regexed", "contexte"], "use_features": true, "label_var": "label", "drop_center": true, "num_workers": 12, "prefetch_factor": 4, "pin_memory": true}}, "NUM_CLASSES": 2, "INPUT_DIM": 128, "HIDDEN_DIM": 768, "MIN_DELTA": 0.001, "time_elapsed": 180.74059859800036, "metrics": {"log_loss": 0.6040693340870287, "accuracy": 0.6680813401721067, "balanced_accuracy": 0.6563209366229179, "recall": 0.5842891369730336, "precision": 0.6074030894782863, "f1_score": 0.5956219551802534, "AUC": 0.7193478317685408, "jaccard_weighted": 0.42411796266489055, "matthews_weighted": 0.3144907643620402, "hamming_loss": 0.33191865982789326, "confusion_matrix": [[39728, 14817], [16310, 22924]], "confusion_matrix_true_normed": [[0.7283527362728023, 0.2716472637271977], [0.4157108630269664, 0.5842891369730336]], "confusion_matrix_pred_normed": [[0.7089474999107749, 0.3925969105217138], [0.2910525000892252, 0.6074030894782863]], "confusion_matrix_all_normed": [[0.42363428912656353, 0.1579991256038132], [0.17391953422408002, 0.24444705104554323]]}}
